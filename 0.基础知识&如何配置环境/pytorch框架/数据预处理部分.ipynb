{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 自定义数据集建立\n",
    " 数据集有可以直接从网上下载的，但大多数数据集实际上还需要手动处理，按照pytorch训练的格式写进去"
   ],
   "id": "7cc338b8fae00f5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T06:33:58.015875Z",
     "start_time": "2025-12-24T06:33:47.895839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "class Self_Dataset(Dataset):\n",
    "    def __init__(self,datas,lables):\n",
    "        self.datas = datas\n",
    "        self.lables = lables\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lables)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        data=self.datas[item]\n",
    "        label=self.labels[item]\n",
    "        return data,label"
   ],
   "id": "988923ea3d4f589",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "  这基本上是一个最基础的框架，实际上要运用的会比这个要复杂，但是只要记住，自定义数据需要继承torch.utils.data中的Dataset类，并且重写三个函数即可，重点是第三个函数，他决定了数据集返回什么，一般是输入数据，加标签。\n",
    "  ### 标签\n",
    "  标签部分只用写一个下标i，表示对应第i个分类结果是正确答案，在损失函数内部会自动处理为独热编码"
   ],
   "id": "dd33d8435d3040c7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 模拟建立一个自己的数据集\n",
    "这里选择创建100组数据，每一组数据有两个值(x,y),代表在空间坐标系的坐标，现在我们想训练把数据分为两类，一类在y=x^2方函数的上方，另一组在下方，所以就要对它们贴上不同的标签，上方标签为0，下方标签为1"
   ],
   "id": "eca06b2ba5df84c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T06:56:12.889951Z",
     "start_time": "2025-12-24T06:56:12.830471Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datas=torch.rand(1000,2)\n",
    "#这里是贴标签的函数\n",
    "def get_label(data):\n",
    "    if data[0]*data[0] - data[1] >=0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "labels=torch.tensor([get_label(data)for data in datas ])\n",
    "class XY_Dataset(Dataset):\n",
    "    def __init__(self,datas,labels):\n",
    "        self.datas = datas\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        data=self.datas[item]\n",
    "        label=self.labels[item]\n",
    "        return data,label\n",
    "\n",
    "xy_dataset=XY_Dataset(datas,labels)\n",
    "print(xy_dataset[0])\n"
   ],
   "id": "a8e6c7003c325cd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.2787, 0.0385]), tensor(0))\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 划分训练集和测试集\n",
    "这一步并不是每次都需要，但有些时候拿到的数据并不会区分训练集和测试集，这时候就需要手动划分"
   ],
   "id": "9526c6cfc4143388"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T06:56:14.912188Z",
     "start_time": "2025-12-24T06:56:14.872181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p=0.9\n",
    "train_size=int(len(xy_dataset)*p)\n",
    "test_size=len(xy_dataset)-train_size"
   ],
   "id": "75897a1bcd29a457",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "注意，这里需要把结果转为整数先，因为总数*0.9可能是小数",
   "id": "6197fe3207ba1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T06:57:32.932093Z",
     "start_time": "2025-12-24T06:57:32.924285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset,test_dataset=torch.utils.data.random_split(xy_dataset,[train_size,test_size])\n",
    "print(f\"train size: {len(train_dataset) }\")\n",
    "print(f\"test size: {len(test_dataset)}\")"
   ],
   "id": "df8f5e546236bdc0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 900\n",
      "test size: 100\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 把数据集捆成批次\n",
    "这里要用到dataloader函数,可以指定1批的大小是多大，是否打乱，一般只有训练集需要打乱，测试集不用"
   ],
   "id": "43499d790610caa0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:13:11.462520Z",
     "start_time": "2025-12-24T07:13:11.457284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "#第一个参数传数据集，batch_size指定大小，shuffle指定是否序，num_workers指定进程数，可以加快训练,\n",
    "train_loader=DataLoader(train_dataset,batch_size=16,shuffle=True,num_workers=0)\n",
    "test_loader=DataLoader(test_dataset,batch_size=16,shuffle=False,num_workers=0)"
   ],
   "id": "5eea6813775af976",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "在GPU环境下，设置pin_memory=True，可以加快训练，原理跳过。",
   "id": "cb3dcf39f4e95c12"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "以上就是最基础的数据处理部分了，在实际训练中往往会复杂多变，但是只要把握好自定义数据集，捆绑的逻辑就可以了",
   "id": "69d08b3dc307a154"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:13:51.104004Z",
     "start_time": "2025-12-24T07:13:51.085210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for datas_batch,labels_batch in train_loader:\n",
    "    #查看一批数据\n",
    "    for data in zip(datas_batch,labels_batch):\n",
    "        print(data)\n",
    "    break"
   ],
   "id": "a887ef072c13db6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.5075, 0.5707]), tensor(1))\n",
      "(tensor([0.2954, 0.6791]), tensor(1))\n",
      "(tensor([0.8238, 0.2523]), tensor(0))\n",
      "(tensor([0.8660, 0.2553]), tensor(0))\n",
      "(tensor([0.6617, 0.0438]), tensor(0))\n",
      "(tensor([0.0682, 0.4964]), tensor(1))\n",
      "(tensor([0.2097, 0.8135]), tensor(1))\n",
      "(tensor([0.4283, 0.8257]), tensor(1))\n",
      "(tensor([0.7680, 0.0088]), tensor(0))\n",
      "(tensor([0.8102, 0.5122]), tensor(0))\n",
      "(tensor([0.3818, 0.3241]), tensor(1))\n",
      "(tensor([0.7965, 0.8039]), tensor(1))\n",
      "(tensor([0.7986, 0.1838]), tensor(0))\n",
      "(tensor([0.8160, 0.5937]), tensor(0))\n",
      "(tensor([0.7581, 0.7989]), tensor(1))\n",
      "(tensor([0.6741, 0.0443]), tensor(0))\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### collate_fn函数",
   "id": "83ae4cf7cdac9143"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "这个函数指定了以什么样的规则去把数据捆起来，虽然我对这个函数用的不多，但是不妨碍它很重要。有时候数据并不是只有输入和标签的，像之前做Embedding时，还要传入offset，而这一步就是在捆绑时完成的,这里写一个简单的捆绑处理函数，体会这个函数的作用。\n",
    "\n",
    "传入的batch有n个，batch[0]有着第一个数据的输入和标签，batch[0][0]表示第一个数据的输入"
   ],
   "id": "908c0ed6c1cc7a6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T07:40:54.710806Z",
     "start_time": "2025-12-24T07:40:54.651559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def collate_fn(batch):\n",
    "    datas=[]\n",
    "    for x in batch:\n",
    "        data=x[0]\n",
    "        data[0]+=1#使得所有的x+1\n",
    "        datas.append(data)\n",
    "\n",
    "    labels=[x[1] for x in batch]\n",
    "    return datas,labels\n",
    "new_train_loader=DataLoader(train_dataset,batch_size=16,shuffle=True,num_workers=0,collate_fn=collate_fn)\n",
    "for data,label in new_train_loader:\n",
    "    for _ in zip(data,label):\n",
    "        print(_)\n",
    "    break\n"
   ],
   "id": "1ae72b66c87426ca",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1.0101, 0.2745]), tensor(1))\n",
      "(tensor([1.7547, 0.7776]), tensor(1))\n",
      "(tensor([1.9996, 0.0984]), tensor(0))\n",
      "(tensor([1.3127, 0.5011]), tensor(1))\n",
      "(tensor([1.0422, 0.3993]), tensor(1))\n",
      "(tensor([1.2405, 0.1872]), tensor(1))\n",
      "(tensor([1.2198, 0.2986]), tensor(1))\n",
      "(tensor([1.7778, 0.2667]), tensor(0))\n",
      "(tensor([1.7618, 0.7264]), tensor(1))\n",
      "(tensor([1.2384, 0.9681]), tensor(1))\n",
      "(tensor([1.7833, 0.2173]), tensor(0))\n",
      "(tensor([1.6753, 0.7863]), tensor(1))\n",
      "(tensor([1.8116, 0.7223]), tensor(1))\n",
      "(tensor([1.1937, 0.4745]), tensor(1))\n",
      "(tensor([1.4016, 0.3865]), tensor(1))\n",
      "(tensor([1.9148, 0.1046]), tensor(0))\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "上面的collate_fn就是负责把所以输入数据的x加上了1，当然在实际应用中，它能做的比这多的多！",
   "id": "7a320b9577158a14"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 用内置的数据集\n",
    "pytorch已经给我们提供了很多内置的数据集，这里以许多计算机视觉中的数据集为例子"
   ],
   "id": "62c202d482fcb53b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T08:01:52.006846Z",
     "start_time": "2025-12-24T08:01:42.077861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "path=\"Dataset\"\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "dataset=torchvision.datasets.MNIST(root=path,train=True,transform=transforms.ToTensor(),download=True)"
   ],
   "id": "ccb15162d7208016",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "76cb7031a68d29c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 数据预处理和增强\n",
    "这一部分要用到`torch.transforms`里面的函数，一般可以包括调整大小，转为张量，标准化\n"
   ],
   "id": "b45329882eb62489"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 定义数据预处理的流水线\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # 将图像调整为 128x128\n",
    "    transforms.ToTensor(),  # 将图像转换为张量\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # 标准化\n",
    "])"
   ],
   "id": "7aaaedae26d4bf5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ToTensor\n",
    "输入一般是PIL图像或者numpy数组，形状需要是HWC类型，使用这个函数后，会把HWC转为CHW，同时把0-255的像素值归一化到0-1内"
   ],
   "id": "1324141b8b17a19c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Compose\n",
    "这个函数用来把不同的transforms函数组合，使用时要注意顺序,里面用列表组装"
   ],
   "id": "b641a142aa0dc2a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])",
   "id": "7cfcfef0d0605eda"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "如果是对自己的数据集处理的话,可以把transform一起传进去。",
   "id": "82a008a68f30e718"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T09:24:00.660233Z",
     "start_time": "2025-12-24T09:24:00.591256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Self_Dataset(Dataset):\n",
    "    def __init__(self,images_list,lables,transform):\n",
    "        self.images = images_list\n",
    "        self.lables = lables\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.lables)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image=self.images[item]\n",
    "        image_tensor=self.transform(image)\n",
    "        label=self.labels[item]\n",
    "        return image_tensor,label"
   ],
   "id": "b18892cf724a54b2",
   "outputs": [],
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
