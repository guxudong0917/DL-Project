{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 如何写一个训练的代码\n",
    "一个训练部分的代码其实说简单也很简单，我觉得就可以分为以下几步：\n",
    "\n",
    "1. 选择损失函数和优化器。\n",
    "2. 把数据和模型加载到设备上。\n",
    "3. 输入神经网络获得输出，计算损失。\n",
    "4. 反向传播，梯度清零。"
   ],
   "id": "b08806cc02e03ecc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 这里先把前面的代码给复制过来哈",
   "id": "fabea62ca4119adf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T12:59:17.138483Z",
     "start_time": "2025-12-24T12:59:17.014296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "datas=torch.rand(1000,2)\n",
    "#这里是贴标签的函数\n",
    "def get_label(data):\n",
    "    if data[0]*data[0] - data[1] >=0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "labels=[get_label(data)for data in datas]\n",
    "\n",
    "class XY_Dataset(Dataset):\n",
    "    def __init__(self,datas,labels):\n",
    "        self.datas = datas\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        data=self.datas[item]\n",
    "        label=self.labels[item]\n",
    "        label_tensor=torch.tensor(label,dtype=torch.float32)\n",
    "        return data,label_tensor\n",
    "\n",
    "xy_dataset=XY_Dataset(datas,labels)\n",
    "#划分数据集\n",
    "p=0.9\n",
    "train_size=int(len(xy_dataset)*p)\n",
    "test_size=len(xy_dataset)-train_size\n",
    "train_dataset,test_dataset=torch.utils.data.random_split(xy_dataset,[train_size,test_size])\n",
    "print(f\"train size: {len(train_dataset) }\")\n",
    "print(f\"test size: {len(test_dataset)}\")\n",
    "\n",
    "#第一个参数传数据集，batch_size指定大小，shuffle指定是否序，num_workers指定进程数，可以加快训练,\n",
    "train_loader=DataLoader(train_dataset,batch_size=16,shuffle=True,num_workers=0)\n",
    "test_loader=DataLoader(test_dataset,batch_size=16,shuffle=False,num_workers=0)"
   ],
   "id": "c88d37f85675635c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 900\n",
      "test size: 100\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T12:59:21.746991Z",
     "start_time": "2025-12-24T12:59:21.738027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        #用完成父类的初始化，不可以省略\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1=nn.Linear(input_size,hidden_size)\n",
    "        self.layer2=nn.Linear(hidden_size,output_size)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        h=self.relu(self.layer1(x))\n",
    "        result=self.sigmoid(self.layer2(h))\n",
    "        return result"
   ],
   "id": "41e8df932aaaef3e",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 训练部分\n",
    "查看设备，并且把模型放到设备上(我的电脑不能用cuda..麻了...)"
   ],
   "id": "367a3b88bbff4b2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T15:30:49.494919Z",
     "start_time": "2025-12-24T15:30:49.391888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "model = Net(2,15,1)\n",
    "model = model.to(device)"
   ],
   "id": "9026dadf11e5ca5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 设置损失函数和优化器",
   "id": "5705679d19410202"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T15:30:50.853212Z",
     "start_time": "2025-12-24T15:30:50.832492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "loss_fn=nn.BCELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)"
   ],
   "id": "1ac1348f0138b990",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 损失函数\n",
    "关于损失函数有个注意事项:\n",
    "### 最后一层加上了sigmoid函数\n",
    "二分类是BCE_Loss\n",
    "### 最后一层没有sigmoid/softmax激活\n",
    "多分类是`nn.CrossEntropyLoss`多分类交叉熵里面包含了softmax不用再在神经网络中添加，二分类是`nn.BCEWithLogitsLoss()`，"
   ],
   "id": "efc7efa18a04470c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 将数据加载到设备/计算损失/反向传播\n",
    "这里可以注意的点可太多了:\n",
    "1. 首先在每一轮开始前需要把model设置为训练模式,这一步是非常有必要的！！因为只有设置了这一步，dropout层和batchnorm层才会生效。\n",
    "2. 数据和标签都要放到设备上\n",
    "3. 每次反向传播完后要将梯度清零\n",
    "4. 定期打印loss\n",
    "\n",
    "### 刚刚犯错误了\n",
    "1. 我在设计神经网络时把输出层设置为了2，因为我想的总共要分为两类，但是当我用了BCE_Loss时，对应的输出应该只有一个。\n",
    "\n",
    "BCELOSS:`−[ylog(p)+(1−y)log(1−p)]`,默认p是正类的概率。\n",
    "\n",
    "当我的输出设置为2时，实际上应该用多分类交叉熵，这样会分别计算是负类和正类的概率。\n",
    "\n",
    "2. 我的output是[16，1],labels是[16],需要统一维度，这里通过squeeze去除output第一维度\n",
    "\n",
    "3. 我的label处理时写的时labels=torch.tensor([get_label(data)for data in datas])，但是标准写法应该是在getitem中转为tensor，BCE用float32，CE用long类型"
   ],
   "id": "6a36e063c3f3ecf5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 用tensorboard绘制损失",
   "id": "eaa28be8de15db6e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. `SummaryWriter(\"\")`里面指定保存路径\n",
    "2. `writer.add_scalar(name,记录的值，global_step)` 记录损失，根据name部分来画图\n",
    "3. 要手动标注global,step。\n",
    "4. 查看数据：tensorboard --logdir=绝对路径\n",
    "5. 注意，要想用全局变量，并且在多次调用时续写的话，就不能把他当参数传入，不然只会局部修改，在修改前要声明"
   ],
   "id": "6cd40f62527cb235"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T14:39:38.468937Z",
     "start_time": "2025-12-24T14:39:38.459916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "global_step=0"
   ],
   "id": "99efc76161e1cbcf",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T14:39:39.298275Z",
     "start_time": "2025-12-24T14:39:39.280586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs=30\n",
    "print(train_dataset[0])\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def train(model,train_loader,device,epochs,loss_fn=nn.BCELoss(),optimizer=None):\n",
    "    global global_step\n",
    "    writer=SummaryWriter(\"./train_loss_log\")\n",
    "    optimizer=optimizer or torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for i,(datas,labels) in enumerate(train_loader):\n",
    "            datas=datas.to(device)\n",
    "            labels=labels.to(device)\n",
    "            output=model(datas)\n",
    "            output=output.squeeze(1)\n",
    "            loss=loss_fn(output,labels)\n",
    "            #清理梯度\n",
    "            optimizer.zero_grad()\n",
    "            #反向传播\n",
    "            loss.backward()\n",
    "            #更新权重\n",
    "            optimizer.step()\n",
    "            global_step+=1\n",
    "            if i%10==0:\n",
    "                print(f\"epoch:{epoch}_{i},loss:{loss}\")\n",
    "                writer.add_scalar(\"Loss\",loss,global_step)\n",
    "\n",
    "        if epoch % 10==0:\n",
    "            torch.save({\n",
    "                \"epoch\":epoch,\n",
    "                \"model_state_dict\":model.state_dict(),\n",
    "                \"optimizer_state_dict\":optimizer.state_dict(),\n",
    "                \"loss\":loss.item(),\n",
    "            },f\"./checkpoint/checkpoint_epoch{epoch}_loss{loss.item()}.pth\")\n",
    "\n"
   ],
   "id": "c087d09679ce24fb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.7741, 0.5030]), tensor(0.))\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T14:42:36.329696Z",
     "start_time": "2025-12-24T14:42:33.910136Z"
    }
   },
   "cell_type": "code",
   "source": "train(model,train_loader,device, epochs,loss_fn)",
   "id": "621fe78d46dc18bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0_0,loss:0.08425977826118469\n",
      "epoch:0_10,loss:0.10224828124046326\n",
      "epoch:0_20,loss:0.16538560390472412\n",
      "epoch:0_30,loss:0.1344987452030182\n",
      "epoch:0_40,loss:0.17102794349193573\n",
      "epoch:0_50,loss:0.3085537850856781\n",
      "epoch:1_0,loss:0.11063604056835175\n",
      "epoch:1_10,loss:0.08869641274213791\n",
      "epoch:1_20,loss:0.06605039536952972\n",
      "epoch:1_30,loss:0.07933147996664047\n",
      "epoch:1_40,loss:0.21494369208812714\n",
      "epoch:1_50,loss:0.23778650164604187\n",
      "epoch:2_0,loss:0.06790468096733093\n",
      "epoch:2_10,loss:0.15987886488437653\n",
      "epoch:2_20,loss:0.16492272913455963\n",
      "epoch:2_30,loss:0.14934711158275604\n",
      "epoch:2_40,loss:0.08998394757509232\n",
      "epoch:2_50,loss:0.1396142989397049\n",
      "epoch:3_0,loss:0.22788046300411224\n",
      "epoch:3_10,loss:0.08856367319822311\n",
      "epoch:3_20,loss:0.13846871256828308\n",
      "epoch:3_30,loss:0.09153831005096436\n",
      "epoch:3_40,loss:0.11660245805978775\n",
      "epoch:3_50,loss:0.20029005408287048\n",
      "epoch:4_0,loss:0.16817080974578857\n",
      "epoch:4_10,loss:0.14793434739112854\n",
      "epoch:4_20,loss:0.10069829225540161\n",
      "epoch:4_30,loss:0.18366087973117828\n",
      "epoch:4_40,loss:0.1151028424501419\n",
      "epoch:4_50,loss:0.04670584946870804\n",
      "epoch:5_0,loss:0.0662454143166542\n",
      "epoch:5_10,loss:0.1941809356212616\n",
      "epoch:5_20,loss:0.138818621635437\n",
      "epoch:5_30,loss:0.21668969094753265\n",
      "epoch:5_40,loss:0.19277392327785492\n",
      "epoch:5_50,loss:0.11765734106302261\n",
      "epoch:6_0,loss:0.06338916718959808\n",
      "epoch:6_10,loss:0.13081349432468414\n",
      "epoch:6_20,loss:0.17361637949943542\n",
      "epoch:6_30,loss:0.18616986274719238\n",
      "epoch:6_40,loss:0.12332027405500412\n",
      "epoch:6_50,loss:0.09598927199840546\n",
      "epoch:7_0,loss:0.11178629845380783\n",
      "epoch:7_10,loss:0.1114770919084549\n",
      "epoch:7_20,loss:0.2195357233285904\n",
      "epoch:7_30,loss:0.15081706643104553\n",
      "epoch:7_40,loss:0.21248379349708557\n",
      "epoch:7_50,loss:0.07192974537611008\n",
      "epoch:8_0,loss:0.300411581993103\n",
      "epoch:8_10,loss:0.14079409837722778\n",
      "epoch:8_20,loss:0.09804396331310272\n",
      "epoch:8_30,loss:0.21706505119800568\n",
      "epoch:8_40,loss:0.06748110055923462\n",
      "epoch:8_50,loss:0.08094266057014465\n",
      "epoch:9_0,loss:0.13046522438526154\n",
      "epoch:9_10,loss:0.05556408688426018\n",
      "epoch:9_20,loss:0.16624580323696136\n",
      "epoch:9_30,loss:0.09488099813461304\n",
      "epoch:9_40,loss:0.26519349217414856\n",
      "epoch:9_50,loss:0.2009699046611786\n",
      "epoch:10_0,loss:0.0911417305469513\n",
      "epoch:10_10,loss:0.08807087689638138\n",
      "epoch:10_20,loss:0.20037195086479187\n",
      "epoch:10_30,loss:0.0553191676735878\n",
      "epoch:10_40,loss:0.06330626457929611\n",
      "epoch:10_50,loss:0.17002543807029724\n",
      "epoch:11_0,loss:0.054116569459438324\n",
      "epoch:11_10,loss:0.17599964141845703\n",
      "epoch:11_20,loss:0.05873195081949234\n",
      "epoch:11_30,loss:0.17686496675014496\n",
      "epoch:11_40,loss:0.11079572141170502\n",
      "epoch:11_50,loss:0.14524897933006287\n",
      "epoch:12_0,loss:0.13465160131454468\n",
      "epoch:12_10,loss:0.06273677945137024\n",
      "epoch:12_20,loss:0.018881309777498245\n",
      "epoch:12_30,loss:0.08923901617527008\n",
      "epoch:12_40,loss:0.19092264771461487\n",
      "epoch:12_50,loss:0.0863582193851471\n",
      "epoch:13_0,loss:0.12693989276885986\n",
      "epoch:13_10,loss:0.08525768667459488\n",
      "epoch:13_20,loss:0.14305177330970764\n",
      "epoch:13_30,loss:0.14650008082389832\n",
      "epoch:13_40,loss:0.12914206087589264\n",
      "epoch:13_50,loss:0.04534897208213806\n",
      "epoch:14_0,loss:0.1414511799812317\n",
      "epoch:14_10,loss:0.13045410811901093\n",
      "epoch:14_20,loss:0.09013791382312775\n",
      "epoch:14_30,loss:0.13414250314235687\n",
      "epoch:14_40,loss:0.06210208684206009\n",
      "epoch:14_50,loss:0.14536356925964355\n",
      "epoch:15_0,loss:0.07037286460399628\n",
      "epoch:15_10,loss:0.05855381488800049\n",
      "epoch:15_20,loss:0.0712428092956543\n",
      "epoch:15_30,loss:0.09371191263198853\n",
      "epoch:15_40,loss:0.08262652158737183\n",
      "epoch:15_50,loss:0.09175362437963486\n",
      "epoch:16_0,loss:0.07435833662748337\n",
      "epoch:16_10,loss:0.1616101861000061\n",
      "epoch:16_20,loss:0.2616681456565857\n",
      "epoch:16_30,loss:0.09639213234186172\n",
      "epoch:16_40,loss:0.117357037961483\n",
      "epoch:16_50,loss:0.09974513202905655\n",
      "epoch:17_0,loss:0.11536797881126404\n",
      "epoch:17_10,loss:0.065843865275383\n",
      "epoch:17_20,loss:0.08857666701078415\n",
      "epoch:17_30,loss:0.08234119415283203\n",
      "epoch:17_40,loss:0.14392626285552979\n",
      "epoch:17_50,loss:0.18009725213050842\n",
      "epoch:18_0,loss:0.04101502150297165\n",
      "epoch:18_10,loss:0.058391209691762924\n",
      "epoch:18_20,loss:0.05811619013547897\n",
      "epoch:18_30,loss:0.135096937417984\n",
      "epoch:18_40,loss:0.05339343473315239\n",
      "epoch:18_50,loss:0.09693283587694168\n",
      "epoch:19_0,loss:0.08262360841035843\n",
      "epoch:19_10,loss:0.1644565463066101\n",
      "epoch:19_20,loss:0.1879703551530838\n",
      "epoch:19_30,loss:0.15575215220451355\n",
      "epoch:19_40,loss:0.18911750614643097\n",
      "epoch:19_50,loss:0.27795618772506714\n",
      "epoch:20_0,loss:0.15810924768447876\n",
      "epoch:20_10,loss:0.11417333036661148\n",
      "epoch:20_20,loss:0.17746756970882416\n",
      "epoch:20_30,loss:0.05424443632364273\n",
      "epoch:20_40,loss:0.10258059203624725\n",
      "epoch:20_50,loss:0.18641988933086395\n",
      "epoch:21_0,loss:0.025664275512099266\n",
      "epoch:21_10,loss:0.05192456394433975\n",
      "epoch:21_20,loss:0.07544601708650589\n",
      "epoch:21_30,loss:0.026596762239933014\n",
      "epoch:21_40,loss:0.12051036953926086\n",
      "epoch:21_50,loss:0.08890935033559799\n",
      "epoch:22_0,loss:0.10363763570785522\n",
      "epoch:22_10,loss:0.040560152381658554\n",
      "epoch:22_20,loss:0.07367954403162003\n",
      "epoch:22_30,loss:0.10083074867725372\n",
      "epoch:22_40,loss:0.07774002850055695\n",
      "epoch:22_50,loss:0.06425296515226364\n",
      "epoch:23_0,loss:0.16493965685367584\n",
      "epoch:23_10,loss:0.18966802954673767\n",
      "epoch:23_20,loss:0.09357084333896637\n",
      "epoch:23_30,loss:0.11096338927745819\n",
      "epoch:23_40,loss:0.13971108198165894\n",
      "epoch:23_50,loss:0.08990789204835892\n",
      "epoch:24_0,loss:0.12356586009263992\n",
      "epoch:24_10,loss:0.06647595763206482\n",
      "epoch:24_20,loss:0.08726204186677933\n",
      "epoch:24_30,loss:0.09821324050426483\n",
      "epoch:24_40,loss:0.12319319695234299\n",
      "epoch:24_50,loss:0.03955084830522537\n",
      "epoch:25_0,loss:0.0902029424905777\n",
      "epoch:25_10,loss:0.08089004456996918\n",
      "epoch:25_20,loss:0.2093380242586136\n",
      "epoch:25_30,loss:0.07542489469051361\n",
      "epoch:25_40,loss:0.057671062648296356\n",
      "epoch:25_50,loss:0.06298691779375076\n",
      "epoch:26_0,loss:0.062322404235601425\n",
      "epoch:26_10,loss:0.03455061465501785\n",
      "epoch:26_20,loss:0.07006269693374634\n",
      "epoch:26_30,loss:0.0745995044708252\n",
      "epoch:26_40,loss:0.16578733921051025\n",
      "epoch:26_50,loss:0.19892391562461853\n",
      "epoch:27_0,loss:0.1738145649433136\n",
      "epoch:27_10,loss:0.04167420044541359\n",
      "epoch:27_20,loss:0.17907753586769104\n",
      "epoch:27_30,loss:0.1484106183052063\n",
      "epoch:27_40,loss:0.06779977679252625\n",
      "epoch:27_50,loss:0.18931818008422852\n",
      "epoch:28_0,loss:0.10055467486381531\n",
      "epoch:28_10,loss:0.11240272223949432\n",
      "epoch:28_20,loss:0.10564267635345459\n",
      "epoch:28_30,loss:0.06255652010440826\n",
      "epoch:28_40,loss:0.05913924425840378\n",
      "epoch:28_50,loss:0.07942403107881546\n",
      "epoch:29_0,loss:0.10248830169439316\n",
      "epoch:29_10,loss:0.1521822214126587\n",
      "epoch:29_20,loss:0.1010526567697525\n",
      "epoch:29_30,loss:0.025913110002875328\n",
      "epoch:29_40,loss:0.05080895125865936\n",
      "epoch:29_50,loss:0.14581891894340515\n"
     ]
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 接下来是测试代码\n",
    "其实大差不差和训练代码，只有几个需要注意的地方：\n",
    "1. 计算损失时统计全部的损失再算平均\n",
    "2. 切换model.eval()模式"
   ],
   "id": "26750b99ed67fc76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T15:20:44.886805Z",
     "start_time": "2025-12-24T15:20:44.793616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validation(model,test_loader,device,loss_fn=nn.BCELoss()):\n",
    "    model.eval()\n",
    "    model=model.to(device)\n",
    "    test_loss=0\n",
    "    correct=0\n",
    "    test_size=0;\n",
    "    with torch.no_grad():\n",
    "        for i,(datas,labels) in enumerate(test_loader):\n",
    "            datas=datas.to(device)\n",
    "            labels=labels.to(device)\n",
    "            output=model(datas)\n",
    "            output=output.squeeze(1)\n",
    "            result=output>0.5\n",
    "            correct+=torch.sum(result==labels).item()\n",
    "            loss=loss_fn(output,labels)\n",
    "            test_loss+=loss.item()\n",
    "            test_size+=len(labels)\n",
    "\n",
    "    return test_loss/len(test_loader),correct/test_size\n"
   ],
   "id": "f7af397de8a254f0",
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 注意\n",
    "1. 天啊，第一次写的时候没写with torch.no_grad(),在这个阶段是不需要计算图的！"
   ],
   "id": "b54685f52f8ceb99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T13:59:12.699559Z",
     "start_time": "2025-12-24T13:59:12.678058Z"
    }
   },
   "cell_type": "code",
   "source": "validation(model,test_loader,device)",
   "id": "3a8ad7681bb7132c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1113, grad_fn=<DivBackward0>), 0.95)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "可以看到训练效果是不错的",
   "id": "ca3d7e6d3b58cfad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 保存模型\n",
    "保存模型是很重要的，用`torch.save(保存啥,\".pth\")`\n",
    "\n",
    "```python\n",
    "# 保存检查点\n",
    "checkpoint = {\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss,\n",
    "    # 可以添加其他需要保存的信息\n",
    "}\n",
    "```\n",
    "推荐按照这个来，不止保持model的权重，还保存优化器的数值，方便以后接着训练"
   ],
   "id": "c296240cbeb62af8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 早停\n",
    "如果损失连续几轮没有下降，就退出训练，并保存模型"
   ],
   "id": "62a94b23246c5177"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T15:36:31.814251Z",
     "start_time": "2025-12-24T15:36:31.805608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "model = Net(2,15,1)\n",
    "model = model.to(device)\n",
    "import torch.nn as nn\n",
    "\n",
    "loss_fn=nn.BCELoss()"
   ],
   "id": "d8b8083b791aad42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T15:36:46.052240Z",
     "start_time": "2025-12-24T15:36:46.031780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs=30\n",
    "print(train_dataset[0])\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "def train_with_earlystop(model,train_loader,device,epochs,loss_fn=nn.BCELoss(),optimizer=None):\n",
    "    global global_step\n",
    "    writer=SummaryWriter(\"./train_loss_log\")\n",
    "    optimizer=optimizer or torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "    patience=5\n",
    "    min_loss=float(\"inf\")\n",
    "    checkpoint=None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        for i,(datas,labels) in enumerate(train_loader):\n",
    "            datas=datas.to(device)\n",
    "            labels=labels.to(device)\n",
    "            output=model(datas)\n",
    "            output=output.squeeze(1)\n",
    "            loss=loss_fn(output,labels)\n",
    "            #清理梯度\n",
    "            optimizer.zero_grad()\n",
    "            #反向传播\n",
    "            loss.backward()\n",
    "            #更新权重\n",
    "            optimizer.step()\n",
    "            global_step+=1\n",
    "            if i%10==0:\n",
    "                print(f\"epoch:{epoch}_{i},loss:{loss}\")\n",
    "                writer.add_scalar(\"trainLoss\",loss,global_step)\n",
    "\n",
    "\n",
    "        test_loss,acc=validation(model,test_loader,device,loss_fn)\n",
    "        writer.add_scalar(\"Test/Loss\",test_loss,epoch)\n",
    "        writer.add_scalar(\"Test/acc\",acc,epoch)\n",
    "        if test_loss<min_loss:\n",
    "            min_loss=test_loss\n",
    "            patience=5\n",
    "            checkpoint={\n",
    "                \"epoch\":epoch,\n",
    "                \"model_state_dict\":model.state_dict(),\n",
    "                \"optimizer_state_dict\":optimizer.state_dict(),\n",
    "                \"loss\":min_loss,\n",
    "            }\n",
    "        else:\n",
    "            patience-=1\n",
    "        if patience<=0:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "    if checkpoint is not None:\n",
    "        torch.save(checkpoint,f\"./checkpoint/checkpoint_loss{min_loss}.pth\")\n",
    "\n"
   ],
   "id": "fc5a977c48f59dc7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.7741, 0.5030]), tensor(0.))\n"
     ]
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-24T15:36:50.686737Z",
     "start_time": "2025-12-24T15:36:48.305492Z"
    }
   },
   "cell_type": "code",
   "source": "train_with_earlystop(model, train_loader, device, epochs, loss_fn)",
   "id": "65c97efede2bf17b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0_0,loss:0.6809892654418945\n",
      "epoch:0_10,loss:0.7293615937232971\n",
      "epoch:0_20,loss:0.6373035907745361\n",
      "epoch:0_30,loss:0.5946373343467712\n",
      "epoch:0_40,loss:0.6164590716362\n",
      "epoch:0_50,loss:0.6775141358375549\n",
      "epoch:1_0,loss:0.6904236078262329\n",
      "epoch:1_10,loss:0.6591238975524902\n",
      "epoch:1_20,loss:0.5954392552375793\n",
      "epoch:1_30,loss:0.6516152620315552\n",
      "epoch:1_40,loss:0.6285984516143799\n",
      "epoch:1_50,loss:0.596759021282196\n",
      "epoch:2_0,loss:0.6630439162254333\n",
      "epoch:2_10,loss:0.7140003442764282\n",
      "epoch:2_20,loss:0.576139509677887\n",
      "epoch:2_30,loss:0.634880542755127\n",
      "epoch:2_40,loss:0.48055362701416016\n",
      "epoch:2_50,loss:0.6837923526763916\n",
      "epoch:3_0,loss:0.6279343962669373\n",
      "epoch:3_10,loss:0.6583846807479858\n",
      "epoch:3_20,loss:0.6579659581184387\n",
      "epoch:3_30,loss:0.48801344633102417\n",
      "epoch:3_40,loss:0.5295525789260864\n",
      "epoch:3_50,loss:0.5071989893913269\n",
      "epoch:4_0,loss:0.5638716816902161\n",
      "epoch:4_10,loss:0.5995433926582336\n",
      "epoch:4_20,loss:0.6190423965454102\n",
      "epoch:4_30,loss:0.48967796564102173\n",
      "epoch:4_40,loss:0.6711631417274475\n",
      "epoch:4_50,loss:0.5233297944068909\n",
      "epoch:5_0,loss:0.4701453447341919\n",
      "epoch:5_10,loss:0.5569082498550415\n",
      "epoch:5_20,loss:0.5739558935165405\n",
      "epoch:5_30,loss:0.5321851372718811\n",
      "epoch:5_40,loss:0.5592690110206604\n",
      "epoch:5_50,loss:0.4496432840824127\n",
      "epoch:6_0,loss:0.5560993552207947\n",
      "epoch:6_10,loss:0.5290204286575317\n",
      "epoch:6_20,loss:0.6075500249862671\n",
      "epoch:6_30,loss:0.5052105188369751\n",
      "epoch:6_40,loss:0.5167022347450256\n",
      "epoch:6_50,loss:0.30570653080940247\n",
      "epoch:7_0,loss:0.4496353566646576\n",
      "epoch:7_10,loss:0.3436136245727539\n",
      "epoch:7_20,loss:0.33121806383132935\n",
      "epoch:7_30,loss:0.4527743458747864\n",
      "epoch:7_40,loss:0.4347035884857178\n",
      "epoch:7_50,loss:0.44182389974594116\n",
      "epoch:8_0,loss:0.41680338978767395\n",
      "epoch:8_10,loss:0.4478212296962738\n",
      "epoch:8_20,loss:0.32210490107536316\n",
      "epoch:8_30,loss:0.4229060709476471\n",
      "epoch:8_40,loss:0.45398208498954773\n",
      "epoch:8_50,loss:0.3989402651786804\n",
      "epoch:9_0,loss:0.344677209854126\n",
      "epoch:9_10,loss:0.4533748924732208\n",
      "epoch:9_20,loss:0.3885689675807953\n",
      "epoch:9_30,loss:0.4471172094345093\n",
      "epoch:9_40,loss:0.4455680847167969\n",
      "epoch:9_50,loss:0.42971178889274597\n",
      "epoch:10_0,loss:0.3355151414871216\n",
      "epoch:10_10,loss:0.32781195640563965\n",
      "epoch:10_20,loss:0.31698107719421387\n",
      "epoch:10_30,loss:0.3196529150009155\n",
      "epoch:10_40,loss:0.3408730626106262\n",
      "epoch:10_50,loss:0.35493069887161255\n",
      "epoch:11_0,loss:0.3956647515296936\n",
      "epoch:11_10,loss:0.3440726101398468\n",
      "epoch:11_20,loss:0.3375230133533478\n",
      "epoch:11_30,loss:0.26411521434783936\n",
      "epoch:11_40,loss:0.34818190336227417\n",
      "epoch:11_50,loss:0.45065250992774963\n",
      "epoch:12_0,loss:0.40075692534446716\n",
      "epoch:12_10,loss:0.2504756450653076\n",
      "epoch:12_20,loss:0.28357553482055664\n",
      "epoch:12_30,loss:0.28423207998275757\n",
      "epoch:12_40,loss:0.3037938177585602\n",
      "epoch:12_50,loss:0.34109094738960266\n",
      "epoch:13_0,loss:0.34532374143600464\n",
      "epoch:13_10,loss:0.3098902106285095\n",
      "epoch:13_20,loss:0.28251463174819946\n",
      "epoch:13_30,loss:0.3147942125797272\n",
      "epoch:13_40,loss:0.28164970874786377\n",
      "epoch:13_50,loss:0.21912576258182526\n",
      "epoch:14_0,loss:0.3157924711704254\n",
      "epoch:14_10,loss:0.3175196051597595\n",
      "epoch:14_20,loss:0.17682676017284393\n",
      "epoch:14_30,loss:0.2968055307865143\n",
      "epoch:14_40,loss:0.2593075633049011\n",
      "epoch:14_50,loss:0.3231392502784729\n",
      "epoch:15_0,loss:0.372940331697464\n",
      "epoch:15_10,loss:0.300034761428833\n",
      "epoch:15_20,loss:0.3158301115036011\n",
      "epoch:15_30,loss:0.247794970870018\n",
      "epoch:15_40,loss:0.336870014667511\n",
      "epoch:15_50,loss:0.21475274860858917\n",
      "epoch:16_0,loss:0.30936214327812195\n",
      "epoch:16_10,loss:0.1785886585712433\n",
      "epoch:16_20,loss:0.2616286873817444\n",
      "epoch:16_30,loss:0.14800500869750977\n",
      "epoch:16_40,loss:0.1975531131029129\n",
      "epoch:16_50,loss:0.2362838089466095\n",
      "epoch:17_0,loss:0.19023160636425018\n",
      "epoch:17_10,loss:0.3057733178138733\n",
      "epoch:17_20,loss:0.2091463804244995\n",
      "epoch:17_30,loss:0.15161368250846863\n",
      "epoch:17_40,loss:0.24709351360797882\n",
      "epoch:17_50,loss:0.17236767709255219\n",
      "epoch:18_0,loss:0.1960000991821289\n",
      "epoch:18_10,loss:0.3197120130062103\n",
      "epoch:18_20,loss:0.23871180415153503\n",
      "epoch:18_30,loss:0.16938690841197968\n",
      "epoch:18_40,loss:0.1616353541612625\n",
      "epoch:18_50,loss:0.2195001095533371\n",
      "epoch:19_0,loss:0.18930253386497498\n",
      "epoch:19_10,loss:0.16384680569171906\n",
      "epoch:19_20,loss:0.2423366904258728\n",
      "epoch:19_30,loss:0.16351401805877686\n",
      "epoch:19_40,loss:0.12821164727210999\n",
      "epoch:19_50,loss:0.15459044277668\n",
      "epoch:20_0,loss:0.13342377543449402\n",
      "epoch:20_10,loss:0.21903690695762634\n",
      "epoch:20_20,loss:0.19013193249702454\n",
      "epoch:20_30,loss:0.17689324915409088\n",
      "epoch:20_40,loss:0.22448977828025818\n",
      "epoch:20_50,loss:0.19782768189907074\n",
      "epoch:21_0,loss:0.2546061873435974\n",
      "epoch:21_10,loss:0.14298316836357117\n",
      "epoch:21_20,loss:0.2462940663099289\n",
      "epoch:21_30,loss:0.2247602492570877\n",
      "epoch:21_40,loss:0.15963135659694672\n",
      "epoch:21_50,loss:0.18541882932186127\n",
      "epoch:22_0,loss:0.05735418200492859\n",
      "epoch:22_10,loss:0.1318335384130478\n",
      "epoch:22_20,loss:0.13012537360191345\n",
      "epoch:22_30,loss:0.161706805229187\n",
      "epoch:22_40,loss:0.2427995204925537\n",
      "epoch:22_50,loss:0.1654442697763443\n",
      "epoch:23_0,loss:0.28859663009643555\n",
      "epoch:23_10,loss:0.1716964691877365\n",
      "epoch:23_20,loss:0.2234969437122345\n",
      "epoch:23_30,loss:0.13637244701385498\n",
      "epoch:23_40,loss:0.29124143719673157\n",
      "epoch:23_50,loss:0.30175578594207764\n",
      "epoch:24_0,loss:0.13567623496055603\n",
      "epoch:24_10,loss:0.17924192547798157\n",
      "epoch:24_20,loss:0.10603805631399155\n",
      "epoch:24_30,loss:0.18517132103443146\n",
      "epoch:24_40,loss:0.0994115024805069\n",
      "epoch:24_50,loss:0.13912367820739746\n",
      "epoch:25_0,loss:0.1815890073776245\n",
      "epoch:25_10,loss:0.23847763240337372\n",
      "epoch:25_20,loss:0.11395896971225739\n",
      "epoch:25_30,loss:0.1538843810558319\n",
      "epoch:25_40,loss:0.2092037796974182\n",
      "epoch:25_50,loss:0.21961042284965515\n",
      "epoch:26_0,loss:0.2161189168691635\n",
      "epoch:26_10,loss:0.20007076859474182\n",
      "epoch:26_20,loss:0.18349602818489075\n",
      "epoch:26_30,loss:0.17436006665229797\n",
      "epoch:26_40,loss:0.06991253793239594\n",
      "epoch:26_50,loss:0.13100244104862213\n",
      "epoch:27_0,loss:0.24641932547092438\n",
      "epoch:27_10,loss:0.2238672971725464\n",
      "epoch:27_20,loss:0.16686567664146423\n",
      "epoch:27_30,loss:0.10615965723991394\n",
      "epoch:27_40,loss:0.26783615350723267\n",
      "epoch:27_50,loss:0.20212897658348083\n",
      "epoch:28_0,loss:0.21371394395828247\n",
      "epoch:28_10,loss:0.14809587597846985\n",
      "epoch:28_20,loss:0.10416489094495773\n",
      "epoch:28_30,loss:0.21218463778495789\n",
      "epoch:28_40,loss:0.21028241515159607\n",
      "epoch:28_50,loss:0.07872876524925232\n",
      "epoch:29_0,loss:0.06481717526912689\n",
      "epoch:29_10,loss:0.23320241272449493\n",
      "epoch:29_20,loss:0.20776250958442688\n",
      "epoch:29_30,loss:0.26095050573349\n",
      "epoch:29_40,loss:0.13787996768951416\n",
      "epoch:29_50,loss:0.16657748818397522\n"
     ]
    }
   ],
   "execution_count": 139
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d762f93e52b8cd2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 注意\n",
    "1. 早停应该针对测试集的平均loss，而不是单个训练batch的\n",
    "2. 不用每隔十轮保存一次了，太浪费,应该保存loss最小的测试集\n",
    "3. 极端情况可能一轮都不下降，所以开始把checkpoint设为None，检查被记录时才保存"
   ],
   "id": "39cbdff64f2eb82a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
